{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import sqlite3\n",
    "import string\n",
    "from collections import Counter\n",
    "import operator\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains an algorithm to correct sentences. The method is a mix of Peter Norvig article (https://norvig.com/spell-correct.html) and word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=[\"a\",\"abord\",\"absolument\",\"afin\",\"ah\",\"ai\",\"aie\",\"aient\",\"aies\",\"ailleurs\",\"ainsi\",\"ait\",\"allaient\",\"allo\",\"allons\",\"allô\",\"alors\",\"anterieur\",\"anterieure\",\"anterieures\",\"apres\",\"après\",\"as\",\"assez\",\"attendu\",\"au\",\"aucun\",\"aucune\",\"aucuns\",\"aujourd\",\"aujourd'hui\",\"aupres\",\"auquel\",\"aura\",\"aurai\",\"auraient\",\"aurais\",\"aurait\",\"auras\",\"aurez\",\"auriez\",\"aurions\",\"aurons\",\"auront\",\"aussi\",\"autre\",\"autrefois\",\"autrement\",\"autres\",\"autrui\",\"aux\",\"auxquelles\",\"auxquels\",\"avaient\",\"avais\",\"avait\",\"avant\",\"avec\",\"avez\",\"aviez\",\"avions\",\"avoir\",\"avons\",\"ayant\",\"ayez\",\"ayons\",\"b\",\"bah\",\"bas\",\"basee\",\"bat\",\"beau\",\"beaucoup\",\"bien\",\"bigre\",\"bon\",\"boum\",\"bravo\",\"brrr\",\"c\",\"car\",\"ce\",\"ceci\",\"cela\",\"celle\",\"celle-ci\",\"celle-là\",\"celles\",\"celles-ci\",\"celles-là\",\"celui\",\"celui-ci\",\"celui-là\",\"celà\",\"cent\",\"cependant\",\"certain\",\"certaine\",\"certaines\",\"certains\",\"certes\",\"ces\",\"cet\",\"cette\",\"ceux\",\"ceux-ci\",\"ceux-là\",\"chacun\",\"chacune\",\"chaque\",\"cher\",\"chers\",\"chez\",\"chiche\",\"chut\",\"chère\",\"chères\",\"ci\",\"cinq\",\"cinquantaine\",\"cinquante\",\"cinquantième\",\"cinquième\",\"clac\",\"clic\",\"combien\",\"comme\",\"comment\",\"comparable\",\"comparables\",\"compris\",\"concernant\",\"contre\",\"couic\",\"crac\",\"d\",\"da\",\"dans\",\"de\",\"debout\",\"dedans\",\"dehors\",\"deja\",\"delà\",\"depuis\",\"dernier\",\"derniere\",\"derriere\",\"derrière\",\"des\",\"desormais\",\"desquelles\",\"desquels\",\"dessous\",\"dessus\",\"deux\",\"deuxième\",\"deuxièmement\",\"devant\",\"devers\",\"devra\",\"devrait\",\"different\",\"differentes\",\"differents\",\"différent\",\"différente\",\"différentes\",\"différents\",\"dire\",\"directe\",\"directement\",\"dit\",\"dite\",\"dits\",\"divers\",\"diverse\",\"diverses\",\"dix\",\"dix-huit\",\"dix-neuf\",\"dix-sept\",\"dixième\",\"doit\",\"doivent\",\"donc\",\"dont\",\"dos\",\"douze\",\"douzième\",\"dring\",\"droite\",\"du\",\"duquel\",\"durant\",\"dès\",\"début\",\"désormais\",\"e\",\"effet\",\"egale\",\"egalement\",\"egales\",\"eh\",\"elle\",\"elle-même\",\"elles\",\"elles-mêmes\",\"en\",\"encore\",\"enfin\",\"entre\",\"envers\",\"environ\",\"es\",\"essai\",\"est\",\"et\",\"etant\",\"etc\",\"etre\",\"eu\",\"eue\",\"eues\",\"euh\",\"eurent\",\"eus\",\"eusse\",\"eussent\",\"eusses\",\"eussiez\",\"eussions\",\"eut\",\"eux\",\"eux-mêmes\",\"exactement\",\"excepté\",\"extenso\",\"exterieur\",\"eûmes\",\"eût\",\"eûtes\",\"f\",\"fais\",\"faisaient\",\"faisant\",\"fait\",\"faites\",\"façon\",\"feront\",\"fi\",\"flac\",\"floc\",\"fois\",\"font\",\"force\",\"furent\",\"fus\",\"fusse\",\"fussent\",\"fusses\",\"fussiez\",\"fussions\",\"fut\",\"fûmes\",\"fût\",\"fûtes\",\"g\",\"gens\",\"h\",\"ha\",\"haut\",\"hein\",\"hem\",\"hep\",\"hi\",\"ho\",\"holà\",\"hop\",\"hormis\",\"hors\",\"hou\",\"houp\",\"hue\",\"hui\",\"huit\",\"huitième\",\"hum\",\"hurrah\",\"hé\",\"hélas\",\"i\",\"ici\",\"il\",\"ils\",\"importe\",\"j\",\"je\",\"jusqu\",\"jusque\",\"juste\",\"k\",\"l\",\"la\",\"laisser\",\"laquelle\",\"las\",\"le\",\"lequel\",\"les\",\"lesquelles\",\"lesquels\",\"leur\",\"leurs\",\"longtemps\",\"lors\",\"lorsque\",\"lui\",\"lui-meme\",\"lui-même\",\"là\",\"lès\",\"m\",\"ma\",\"maint\",\"maintenant\",\"mais\",\"malgre\",\"malgré\",\"maximale\",\"me\",\"meme\",\"memes\",\"merci\",\"mes\",\"mien\",\"mienne\",\"miennes\",\"miens\",\"mille\",\"mince\",\"mine\",\"minimale\",\"moi\",\"moi-meme\",\"moi-même\",\"moindres\",\"moins\",\"mon\",\"mot\",\"moyennant\",\"multiple\",\"multiples\",\"même\",\"mêmes\",\"n\",\"na\",\"naturel\",\"naturelle\",\"naturelles\",\"ne\",\"neanmoins\",\"necessaire\",\"necessairement\",\"neuf\",\"neuvième\",\"ni\",\"nombreuses\",\"nombreux\",\"nommés\",\"non\",\"nos\",\"notamment\",\"notre\",\"nous\",\"nous-mêmes\",\"nouveau\",\"nouveaux\",\"nul\",\"néanmoins\",\"nôtre\",\"nôtres\",\"o\",\"oh\",\"ohé\",\"ollé\",\"olé\",\"on\",\"ont\",\"onze\",\"onzième\",\"ore\",\"ou\",\"ouf\",\"ouias\",\"oust\",\"ouste\",\"outre\",\"ouvert\",\"ouverte\",\"ouverts\",\"o|\",\"où\",\"p\",\"paf\",\"pan\",\"par\",\"parce\",\"parfois\",\"parle\",\"parlent\",\"parler\",\"parmi\",\"parole\",\"parseme\",\"partant\",\"particulier\",\"particulière\",\"particulièrement\",\"pas\",\"passé\",\"pendant\",\"pense\",\"permet\",\"personne\",\"personnes\",\"peu\",\"peut\",\"peuvent\",\"peux\",\"pff\",\"pfft\",\"pfut\",\"pif\",\"pire\",\"pièce\",\"plein\",\"plouf\",\"plupart\",\"plus\",\"plusieurs\",\"plutôt\",\"possessif\",\"possessifs\",\"possible\",\"possibles\",\"pouah\",\"pour\",\"pourquoi\",\"pourrais\",\"pourrait\",\"pouvait\",\"prealable\",\"precisement\",\"premier\",\"première\",\"premièrement\",\"pres\",\"probable\",\"probante\",\"procedant\",\"proche\",\"près\",\"psitt\",\"pu\",\"puis\",\"puisque\",\"pur\",\"pure\",\"q\",\"qu\",\"quand\",\"quant\",\"quant-à-soi\",\"quanta\",\"quarante\",\"quatorze\",\"quatre\",\"quatre-vingt\",\"quatrième\",\"quatrièmement\",\"que\",\"quel\",\"quelconque\",\"quelle\",\"quelles\",\"quelqu'un\",\"quelque\",\"quelques\",\"quels\",\"qui\",\"quiconque\",\"quinze\",\"quoi\",\"quoique\",\"r\",\"rare\",\"rarement\",\"rares\",\"relative\",\"relativement\",\"remarquable\",\"rend\",\"rendre\",\"restant\",\"reste\",\"restent\",\"restrictif\",\"retour\",\"revoici\",\"revoilà\",\"rien\",\"s\",\"sa\",\"sacrebleu\",\"sait\",\"sans\",\"sapristi\",\"sauf\",\"se\",\"sein\",\"seize\",\"selon\",\"semblable\",\"semblaient\",\"semble\",\"semblent\",\"sent\",\"sept\",\"septième\",\"sera\",\"serai\",\"seraient\",\"serais\",\"serait\",\"seras\",\"serez\",\"seriez\",\"serions\",\"serons\",\"seront\",\"ses\",\"seul\",\"seule\",\"seulement\",\"si\",\"sien\",\"sienne\",\"siennes\",\"siens\",\"sinon\",\"six\",\"sixième\",\"soi\",\"soi-même\",\"soient\",\"sois\",\"soit\",\"soixante\",\"sommes\",\"son\",\"sont\",\"sous\",\"souvent\",\"soyez\",\"soyons\",\"specifique\",\"specifiques\",\"speculatif\",\"stop\",\"strictement\",\"subtiles\",\"suffisant\",\"suffisante\",\"suffit\",\"suis\",\"suit\",\"suivant\",\"suivante\",\"suivantes\",\"suivants\",\"suivre\",\"sujet\",\"superpose\",\"sur\",\"surtout\",\"t\",\"ta\",\"tac\",\"tandis\",\"tant\",\"tardive\",\"te\",\"tel\",\"telle\",\"tellement\",\"telles\",\"tels\",\"tenant\",\"tend\",\"tenir\",\"tente\",\"tes\",\"tic\",\"tien\",\"tienne\",\"tiennes\",\"tiens\",\"toc\",\"toi\",\"toi-même\",\"ton\",\"touchant\",\"toujours\",\"tous\",\"tout\",\"toute\",\"toutefois\",\"toutes\",\"treize\",\"trente\",\"tres\",\"trois\",\"troisième\",\"troisièmement\",\"trop\",\"très\",\"tsoin\",\"tsouin\",\"tu\",\"té\",\"u\",\"un\",\"une\",\"unes\",\"uniformement\",\"unique\",\"uniques\",\"uns\",\"v\",\"va\",\"vais\",\"valeur\",\"vas\",\"vers\",\"via\",\"vif\",\"vifs\",\"vingt\",\"vivat\",\"vive\",\"vives\",\"vlan\",\"voici\",\"voie\",\"voient\",\"voilà\",\"vont\",\"vos\",\"votre\",\"vous\",\"vous-mêmes\",\"vu\",\"vé\",\"vôtre\",\"vôtres\",\"w\",\"x\",\"y\",\"z\",\"zut\",\"à\",\"â\",\"ça\",\"ès\",\"étaient\",\"étais\",\"était\",\"étant\",\"état\",\"étiez\",\"étions\",\"été\",\"étée\",\"étées\",\"étés\",\"êtes\",\"être\",\"ô\"]\n",
    "stop_words+=[\"»\",\"«\",\"''\",\" \",\"–\"]\n",
    "stop_words=set(stop_words)\n",
    "table = str.maketrans(string.punctuation, ' '*len(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= KeyedVectors.load_word2vec_format('../Database/frWac_non_lem_no_postag_no_phrase_200_skip_cut100.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "def remove_tag(text):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', text)\n",
    "    return cleantext\n",
    "\n",
    "def clean_text(text):\n",
    "    text_without_tag=remove_tag(text)\n",
    "    text_without_tag=''.join([i for i in text_without_tag if not i.isdigit()])\n",
    "    text_split=text_without_tag.translate(table).lower().replace('\\n', ' ').split(' ')\n",
    "    text_without_tag=[i for i in text_split if i not in stop_words and i!=\"\"]\n",
    "    return text_without_tag\n",
    "\n",
    "def get_counters(text):\n",
    "    text_without_tag=remove_tag(text)\n",
    "    text_without_tag=''.join([i for i in text_without_tag if not i.isdigit()])\n",
    "    text_split=text_without_tag.translate(table).lower().replace('\\n', ' ').split(' ')    \n",
    "    counter_text=Counter(text_split)\n",
    "    return counter_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-378f72aea312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path='/home/gabriel/Documents/MPRI/Web_Data_Management/wikiextractor-master/text/'\n",
    " #map punctuation to space\n",
    "voc_dict={}\n",
    "count=0\n",
    "\n",
    "for w,i in enumerate(os.listdir(path)):\n",
    "    for j in os.listdir(path+i):\n",
    "        for filename in os.listdir(path+i+'/'+j):\n",
    "            with open(path+i+'/'+j+'/'+filename) as f:\n",
    "                lines = [line.rstrip('\\n') for line in f]\n",
    "            for line_index,line in enumerate(lines):\n",
    "                a=json.loads(line)\n",
    "                if 'text' in a:\n",
    "                    counter_text=get_counters(a['text'])\n",
    "                    for key in counter_text.keys():\n",
    "                        if key not in voc_dict:\n",
    "                            voc_dict[key]=counter_text[key]\n",
    "                        else:\n",
    "                            voc_dict[key]+=counter_text[key]\n",
    "                    count+=1\n",
    "                if count==500000:\n",
    "                    assert(True==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes the frequency of each word\n",
    "\n",
    "length_voc=sum([value for key,value in voc_dict.items()])\n",
    "for key in voc_dict.keys():\n",
    "    voc_dict[key]/=length_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.dumps(voc_dict)\n",
    "f = open(\"../Database/voc_dict.json\",\"w\")\n",
    "f.write(j)\n",
    "f.close()\n",
    "f = open('../Database/voc_dict.json')\n",
    "voc_dict = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['théorie'] ['graphz']\n",
      "0.2107248306274414 0.0045588016510009766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'théorie des graphe'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_correct_sentence(\"théorie des graphz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arret', 'manger'] ['veix']\n",
      "0.10121321678161621 0.13947439193725586\n",
      "je deux arret de manger\n"
     ]
    }
   ],
   "source": [
    "print(get_correct_sentence(\"je veix arret de manger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which modifies a word by doing insert, removal and swapping og characters\n",
    "def modify_word(word):\n",
    "    letters=list(\"abcdefghijklmnopqrstuvwxyzéèàêûöù\")\n",
    "    if type(word)==str:\n",
    "        word_list=list(word)\n",
    "        \n",
    "    modify_1_letter=[]\n",
    "    for i in range(0,len(word_list)):\n",
    "        for j in range(len(letters)):\n",
    "            tmp=list(word)\n",
    "            tmp[i]=letters[j]\n",
    "            modify_1_letter.append(tmp)\n",
    "\n",
    "    swap_one_letter=[]\n",
    "    for i in range(0,len(word_list)-1):\n",
    "        tmp=list(word)\n",
    "        a=word_list[i]\n",
    "        tmp[i]=tmp[i+1]\n",
    "        tmp[i+1]=a\n",
    "        swap_one_letter.append(tmp)\n",
    "    \n",
    "    insert_one_letter=[]\n",
    "    for i in range(0,len(word_list)+1):\n",
    "        for j in range(len(letters)):\n",
    "            tmp=list(word)\n",
    "            tmp.insert(i,letters[j])\n",
    "            insert_one_letter.append(tmp)\n",
    "    \n",
    "    missing_one_letter=[]\n",
    "    for i in range(0,len(word_list)):\n",
    "        tmp=list(word)\n",
    "        del tmp[i]\n",
    "        missing_one_letter.append(tmp)\n",
    "    \n",
    "    return [''.join(i) for i in modify_1_letter+swap_one_letter+insert_one_letter+missing_one_letter]\n",
    "\n",
    "def distance(a,b):\n",
    "    return np.mean((a.reshape(1,-1)-b.reshape(1,-1))**2)\n",
    "\n",
    "def get_correct_sentence(sentence):\n",
    "    path=\"/home/gabriel/Documents/MPRI/Web_Data_Management/search_engine/Database/\"\n",
    "    somme=lambda x:sum([i[1] for i in x])\n",
    "    query_sentence_ori=sentence.lower().replace('\\n', ' ').split(' ')\n",
    "    # query_sentence=sentence.translate(table).lower().replace('\\n', ' ').split(' ')\n",
    "    query_sentence=clean_text(sentence)\n",
    "    conn = sqlite3.connect(path+'Database.db')\n",
    "    c = conn.cursor()\n",
    "    well_spelled_words=[]\n",
    "    mispelled_words=[]\n",
    "    \n",
    "    is_in=lambda x:c.execute(\"Select count(WORD) from Vocabulary where WORD='\"+x+\"';\").fetchone()[0]>0\n",
    "    for i in query_sentence:\n",
    "        if is_in(i):\n",
    "                well_spelled_words.append(i)\n",
    "        else:\n",
    "            mispelled_words.append(i)\n",
    "    print(well_spelled_words,mispelled_words)\n",
    "    if len(mispelled_words)==0:\n",
    "        return \"\"\n",
    "    \n",
    "    w2v_query=np.mean(np.array([model[i] for i in well_spelled_words if i in model]),axis=0)\n",
    "    for word in mispelled_words:\n",
    "        a=time.time()\n",
    "        l=[modify_word(word)]+[modify_word(i) for i in set(modify_word(word))]\n",
    "        reco = set([item for sublist in l for item in sublist if item in voc_dict])\n",
    "        dict1 = Counter(word) \n",
    "        reco_list=[]\n",
    "        b=time.time()\n",
    "        for i in reco:\n",
    "            dict2 = Counter(i)\n",
    "            commonDict = dict1 & dict2\n",
    "            diff1=len(word)/np.sum([value for key,value in commonDict.items()])\n",
    "            diff2=abs(len(word)-len(i))\n",
    "            reco_list.append([i,voc_dict[i]*(1/diff1)*(1/(1+diff2))])\n",
    "        \n",
    "        reco_list=sorted(reco_list,key=lambda x:x[1],reverse=True)\n",
    "        reco_list=[[i[0],float(i[1])/somme(reco_list)] for i in reco_list]\n",
    "        w2v=[[i[0],distance(model[i[0]],w2v_query)] for i in reco_list if i[0] in model]\n",
    "        w2v=[[i[0],i[1]/somme(w2v)] for i in w2v]\n",
    "        both=sorted([[w2v[i][0],0.5*w2v[i][1]+0.5*reco_list[i][1]] for i in range(len(w2v))],key=lambda x:x[1],reverse=True)\n",
    "        if len(both)>0:\n",
    "            query_sentence_ori=[i if i!=word else both[0][0] for i in query_sentence_ori]\n",
    "        c=time.time()\n",
    "        print(b-a,c-b)\n",
    "    conn.close()\n",
    "    return ' '.join(query_sentence_ori)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
