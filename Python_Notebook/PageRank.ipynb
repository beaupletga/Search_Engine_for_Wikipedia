{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.parse\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix,csc_matrix\n",
    "import operator\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook computes 4 things :\n",
    "\n",
    "- the link dict : list of links (id of the forwarding article) in each article\n",
    "- the link dict inverse : list of articles ids leading to an article id\n",
    "- the page rank vector of each article\n",
    "- indices dict : a dictionnary which associates an article id to an row/column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_sentence(sentence):\n",
    "    if len(sentence)>1:\n",
    "        return sentence[0].upper()+sentence[1:]\n",
    "    if len(sentence)==1:\n",
    "        return sentence[0].upper() \n",
    "    return sentence\n",
    "\n",
    "def remove_tag(text):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', text)\n",
    "    return cleantext\n",
    "\n",
    "# transform the name of the links into id of article\n",
    "def compute_name_to_id_of_article(title_dict_inverse,link_dic):\n",
    "    count=0\n",
    "    count2=0\n",
    "    for key,value in link_dict.items():\n",
    "        for i in value:\n",
    "            if i not in title_dict_inverse:\n",
    "                count+=1\n",
    "            else:\n",
    "                count2+=1\n",
    "        id_list= [title_dict_inverse[i] for i in value if i in title_dict_inverse]\n",
    "        link_dict[key]=id_list\n",
    "    print(count,count2)\n",
    "    return link_dic\n",
    "\n",
    "# to avoid duplicates in the links\n",
    "# to avoid self link\n",
    "def clean_links(link_dict):\n",
    "    for key,value in link_dict.items():\n",
    "        link_dict[key]=list(set(value))\n",
    "        if key in link_dict[key]:\n",
    "            link_dict[key].remove(key)\n",
    "    return link_dict\n",
    "\n",
    "def construct_inverse_link_dict(link_dict):\n",
    "    link_dict_inverse={}\n",
    "    for key,value in link_dict.items():\n",
    "        for i in value:\n",
    "            if i in link_dict_inverse:\n",
    "                link_dict_inverse[i].append(key)\n",
    "            else:\n",
    "                link_dict_inverse[i]=[key]\n",
    "    return link_dict_inverse\n",
    "\n",
    "# give a line/column number to each article\n",
    "# because when creating the matrix we don't use the id anymore, only the nb of line/row\n",
    "def get_column_id(title_dict):\n",
    "    indices_dict={}\n",
    "    indices_dict_inverse={}\n",
    "    count=0\n",
    "    for i in title_dict:\n",
    "        indices_dict[i]=count\n",
    "        indices_dict_inverse[count]=i\n",
    "        count+=1\n",
    "    return indices_dict,indices_dict_inverse\n",
    "\n",
    "# prepare the 3 list for the sparse matrix\n",
    "def prepare_data_sparse(title_dict,link_dict,indices_dict):\n",
    "    row=[]\n",
    "    column=[]\n",
    "    data=[]\n",
    "    for i in title_dict:\n",
    "        out_links=link_dict[i]\n",
    "        for j in out_links:\n",
    "            row.append(indices_dict[j])\n",
    "            column.append(indices_dict[i])\n",
    "            data.append(1/len(out_links))\n",
    "    return row,column,data\n",
    "\n",
    "# main algorithm\n",
    "# compute the page rank using the matrix M constructed before and returning a vector r of pagerank of each article\n",
    "def page_rank(title_dict,M,BETA=0.85,eps=1e-5):\n",
    "    n=len(title_dict)\n",
    "    r=np.array([1/n for i in range(n)]).reshape(-1,1)\n",
    "    last_r=np.ones((n,1))\n",
    "    while np.linalg.norm(r - last_r, 2) > eps:\n",
    "        last_r=r\n",
    "        r=BETA*M.dot(r)+((1-BETA)/n)*np.ones((n,1))\n",
    "        r/=np.sum(r)\n",
    "    return r\n",
    "\n",
    "def advice_next_article(title=\"None\",id=\"None\"):\n",
    "    if title!=\"None\":\n",
    "        if title in title_dic_inverse:\n",
    "            id=title_dic_inverse[title]\n",
    "            list_input_links=link_dic_inverse[id]\n",
    "        else:\n",
    "            print(\"Title not in the dict\")\n",
    "            return\n",
    "    elif id!=\"None\":\n",
    "        if id in link_dic_inverse:\n",
    "            list_input_links=link_dic_inverse[id]\n",
    "        else:\n",
    "            print(\"Id not in dict\")\n",
    "            return\n",
    "    \n",
    "    list_input_id=[indides_dic[i] for i in list_input_links]\n",
    "    output=[[indides_dic_inverse[i],r[i]] for i in list_input_id]\n",
    "    output=sorted(output, key=lambda x: x[1],reverse=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "# compute the list of links of each article\n",
    "path='/home/gabriel/Documents/MPRI/Web_Data_Management/wikiextractor-master/text/'\n",
    "title_list=[]\n",
    "text_list=[]\n",
    "title_dict={}\n",
    "title_dict_inverse={}\n",
    "text_dict={}\n",
    "link_dict={}\n",
    "location_dict={}\n",
    "wv_dict={}\n",
    "www_adress={}\n",
    "df=[]\n",
    "count=0\n",
    "for w,i in enumerate(os.listdir(path)):\n",
    "    for j in os.listdir(path+i):\n",
    "        for filename in os.listdir(path+i+'/'+j):\n",
    "            with open(path+i+'/'+j+'/'+filename) as f:\n",
    "                lines = [line.rstrip('\\n') for line in f]\n",
    "            for line_index,line in enumerate(lines):\n",
    "                a=json.loads(line)\n",
    "                if 'text' in a:\n",
    "                    title_dict[a['id']]=a['title']\n",
    "                    title_dict_inverse[a['title']]=a['id']\n",
    "                    urls=re.findall(r'href=[\\'\"]?([^\\'\" >]+)', a['text'])\n",
    "                    title_list_iri=[upper_sentence(urllib.parse.unquote(i)) for i in urls]\n",
    "                    link_dict[a['id']]=title_list_iri\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4566433 30694716\n"
     ]
    }
   ],
   "source": [
    "# at this point, each article is represented in link_dict by a id and a list of titles of articles leading to them \n",
    "\n",
    "#transform the list of article titles by a list of ids\n",
    "link_dict=compute_name_to_id_of_article(title_dict_inverse,link_dict)\n",
    "\n",
    "#removes duplicates in the links of each page\n",
    "link_dict=clean_links(link_dict)\n",
    "\n",
    "#computes the inverse dictionnary of link_dict, where each link has a list of articles ids where each of these\n",
    "# article lead to him\n",
    "link_dict_inverse=construct_inverse_link_dict(link_dict)\n",
    "\n",
    "# transform all the ids into number of column and row (we don't want to use the ids anymore)\n",
    "indices_dict,indices_dict_inverse=get_column_id(title_dict)\n",
    "\n",
    "#prepare the data to compute the Stochastic matrix for Page Rank\n",
    "row,column,data=prepare_data_sparse(title_dict,link_dict,indices_dict)\n",
    "\n",
    "# compute this stochastic matrix, we use the sparse format because this matrix is essentially filled whith 0\n",
    "M=csc_matrix((data, (row, column)), shape=(len(title_dict),len(title_dict)))\n",
    "\n",
    "# computes the page rank vector\n",
    "r=page_rank(title_dict,M,BETA=0.85,eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1487693517020975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4566433/30694716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name_to_id_of_article(title_dict_inverse,link_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calendrier julien 138 [0.00524479]\n",
      "Année (calendrier) 14 [0.0039354]\n",
      "Jour 45 [0.00391385]\n",
      "France 1346 [0.00381026]\n",
      "États-Unis 793 [0.00365807]\n",
      "Calendrier grégorien 89 [0.00332039]\n",
      "Lettre dominicale 19 [0.00257525]\n",
      "31 décembre 8 [0.00255353]\n",
      "Année commune commençant un vendredi 5 [0.00210453]\n",
      "Année commune commençant un lundi 5 [0.00189827]\n",
      "Année commune commençant un mercredi 5 [0.00189555]\n",
      "Année commune commençant un samedi 10 [0.00176511]\n",
      "Année commune commençant un dimanche 5 [0.00172646]\n",
      "Année commune commençant un jeudi 6 [0.00170424]\n",
      "Année commune commençant un mardi 5 [0.00169258]\n"
     ]
    }
   ],
   "source": [
    "s=sorted(range(len(r)), key=lambda k: r[k],reverse=True)\n",
    "for i in range(15):\n",
    "    print(title_dict[indices_dict_inverse[s[i]]],len(link_dict[indices_dict_inverse[s[i]]]),r[s[i]])\n",
    "# print(title_dic[indides_dic_inverse[np.argmax(r)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json.dumps(link_dict_inverse)\n",
    "f = open(\"../Database/link_dict_inverse.json\",\"w\")\n",
    "f.write(j)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../Database/r.npy\",r)\n",
    "j = json.dumps(indices_dict)\n",
    "f = open(\"../Database/indices_dict.json\",\"w\")\n",
    "f.write(j)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
